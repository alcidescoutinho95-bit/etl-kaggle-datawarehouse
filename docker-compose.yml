# version: '3.8'

x-spark-common: &spark-common
  image: wlcamargo/spark-master
  networks:
    - sparkanos

# x-spark-common: &spark-common
#   build:
#     context: .
#     dockerfile: Dockerfile.spark-master
#   networks:
#     - sparkanos

services: 
  # ----------------
  # Postgres
  # ----------------
  postgres:
    hostname: postgres
    image: postgres:14
    environment:
      POSTGRES_USER: airflow
      POSTGRES_PASSWORD: airflow
      POSTGRES_DB: airflow
    volumes:
      - postgres_data:/var/lib/postgresql/data
    networks: 
      - sparkanos

  # ----------------
  # MinIO
  # ----------------
  minio: 
    hostname: minio 
    container_name: minio 
    image: 'minio/minio:RELEASE.2024-01-13T07-53-03Z' 
    ports: 
      - '9000:9000' 
      - '9001:9001' 
    volumes: 
      - minio:/data 
    environment: 
      MINIO_ROOT_USER: minio
      MINIO_ROOT_PASSWORD: minio123
    command: server /data --console-address ":9001" 
    networks: 
      - sparkanos
 
  # ----------------
  # Spark
  # ----------------
  spark-master:
    <<: *spark-common
    hostname: spark-master
    container_name: spark-master
    command: 
      - /bin/sh
      - -c
      - |
        if [ -f /tmp/requirements.txt ]; then
          echo "Instalando dependências Python..."
          pip install --no-cache-dir -r /tmp/requirements.txt
        fi
        /usr/local/spark/sbin/start-master.sh
        start-notebook.sh --NotebookApp.token=''
    volumes:
      - ./conf/util:/util
      - ./conf/env:/env
      - ./src/Notebooks:/home/user/work
      - ./datasets:/home/user/datasets
      - ./requirements.txt:/tmp/requirements.txt:ro
      - C:/Users/senai/Downloads/kaggle.json:/user/.kaggle/kaggle.json:ro
    environment:
      KAGGLE_CONFIG_DIR: /user/.kaggle
    ports:
      - 8889:8888 # Jupyter
      - 8083:8080 # Spark UI
      - 4040:4040 # Spark UI Jobs
      - 7077:7077 # Default port for communication

  # ----------------
  # Airflow infra
  # ----------------
  redis:
    image: redis:latest
    networks: 
      - sparkanos

  airflow-webserver:
    image: apache/airflow:2.9.1
    ports:
      - "8081:8080"
    command: >
      bash -c "
      airflow db init &&
      airflow users create --username admin --password admin --firstname Admin --lastname User --role Admin --email admin@example.com &&
      airflow webserver"
    environment:
      - AIRFLOW__CORE__EXECUTOR=CeleryExecutor
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@postgres:5432/airflow
      - AIRFLOW__CELERY__BROKER_URL=redis://redis:6379/0
      - AIRFLOW__CELERY__RESULT_BACKEND=db+postgresql://airflow:airflow@postgres/airflow
    volumes:
      - ./dags:/opt/airflow/dags
    depends_on:
      - postgres
      - redis
    networks: 
      - sparkanos

  # Airflow Scheduler
  airflow-scheduler:
    image: apache/airflow:2.9.1
    command: scheduler
    environment:
      - AIRFLOW__CORE__EXECUTOR=CeleryExecutor
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@postgres:5432/airflow
    depends_on:
      - airflow-webserver
    networks: 
      - sparkanos

  # Airflow Worker
  airflow-worker:
    image: apache/airflow:2.9.1
    command: celery worker
    environment:
      - AIRFLOW__CORE__EXECUTOR=CeleryExecutor
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@postgres:5432/airflow
      - AIRFLOW__CELERY__BROKER_URL=redis://redis:6379/0
      - AIRFLOW__CELERY__RESULT_BACKEND=db+postgresql://airflow:airflow@postgres/airflow
    depends_on:
      - airflow-webserver
    networks: 
      - sparkanos

# ----------------
# Networks & Volumes
# ----------------
networks: 
  sparkanos: 
    driver: bridge 

volumes: 
  minio:
  postgres_data:  # Nome corrigido - estava como postgres-db-volume
  # postgres-db-volume:  # Se preferir usar este nome, altere também no serviço postgres